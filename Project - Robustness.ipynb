{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Robustness\n",
    "This code was adapted from the code written by Michael Lees and Debraj Roy\n",
    "\n",
    "## Import libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import networkx as nx #import NetworkX\n",
    "import numpy as np #import numpy for ...\n",
    "#force drawing of graphs inline for ipython notebook\n",
    "%matplotlib inline \n",
    "import matplotlib.pyplot as plt #import matplotlib for plotting/drawing grpahs\n",
    "import matplotlib.patches as mpatches #for legends in the graph\n",
    "from __future__ import unicode_literals #allow UTF characters in graph labels\n",
    "import random # for random choice function\n",
    "import copy # this is use for making deep copies of lists\n",
    "from tqdm import tqdm #nice library for progress bars\n",
    "import sys #for writing output to stderr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "with open('vi-wiki-talk.csv', 'rb') as file_handle:\n",
    "    next(file_handle, '')   # skip the header line (NOTE the first list in the CSV file doesn't contain an edge)\n",
    "    V = nx.read_edgelist(file_handle, delimiter='\\t', create_using=nx.DiGraph(), \n",
    "                         nodetype=str, data=(('time', str),), encoding=\"utf-8\")\n",
    "\n",
    "with open('sv-wiki-talk.csv', 'rb') as file_handle:\n",
    "    next(file_handle, '')   # skip the header line (NOTE the first list in the CSV file doesn't contain an edge)\n",
    "    S = nx.read_edgelist(file_handle, delimiter='\\t', create_using=nx.DiGraph(), \n",
    "                         nodetype=str, data=(('time', str),), encoding=\"utf-8\")\n",
    "print \"done\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attack and fail function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fail(G): #a python function that will remove a random node from the graph G\n",
    "    n = random.choice(G.nodes())  #pick a random node\n",
    "    G.remove_node(n) # remove that random node, attached edges automatically removed.\n",
    "    \n",
    "def attack_degree(G): #remove node with maximum degree\n",
    "    degrees = G.degree() # get dcitonary where key is node id, value is degree\n",
    "    max_degree = max(degrees.values()) # find maximum degree value from all nodes\n",
    "    max_keys = [k for k,v in degrees.items() if v==max_degree] #get all nodes who have the maximum degree (may be more than one)\n",
    "    G.remove_node(max_keys[0]) #remove just the first node with max degree, we will remove others next\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimental parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fraction_of_nodes_to_remove = 0.95 # remove until this fraction of all original nodes are removed\n",
    "\n",
    "# For the Vietnamese network\n",
    "NetworkSize_vi = V.order()\n",
    "num_removals_vi = int(fraction_of_nodes_to_remove * NetworkSize_vi) #number of nodes to remove\n",
    "\n",
    "# For the Swedish network\n",
    "NetworkSize_sv = S.order()\n",
    "num_removals_sv = int(fraction_of_nodes_to_remove * NetworkSize_sv) #number of nodes to remove\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measuring Original Network Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def diameter_ave_path_length(G):\n",
    "    # We create our own function to do this so things are slightly faster, \n",
    "    # we can calculate diameter and avg path length at the same time\n",
    "    max_path_length = 0\n",
    "    total = 0.0\n",
    "    for n in G: #iterate over all nodes\n",
    "        path_length=nx.single_source_shortest_path_length(G, n) # generate shortest paths from node n to all others\n",
    "        total += sum(path_length.values()) #total of all shortest paths from n\n",
    "        if max(path_length.values()) > max_path_length: #keep track of longest shortest path we see.\n",
    "            max_path_length = max(path_length.values())         \n",
    "    try:\n",
    "        avg_path_length = total / (G.order()*(G.order() - 1))\n",
    "    except ZeroDivisionError:\n",
    "        avg_path_length = 0.0\n",
    "    return max_path_length, avg_path_length\n",
    "\n",
    "def network_statistics(n):\n",
    "    \"\"\"n is a network\n",
    "    Return diameter (d), average path length (l) and giant component size (s) \"\"\"\n",
    "    \n",
    "    Gcc=sorted(nx.connected_component_subgraphs(n), key = len, reverse=True)\n",
    "    G0=Gcc[0]\n",
    "    d,l = diameter_ave_path_length(G0)\n",
    "    s = float(G0.order()) / float(NetworkSize)\n",
    "    return d,l,s"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
